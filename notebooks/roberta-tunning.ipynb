{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":89576,"databundleVersionId":10931344,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":11178472,"sourceType":"datasetVersion","datasetId":6977146}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- Cell 1: Setup & Configuration (Modified for XLM-RoBERTa) ---\n\n# 1. Install necessary libraries (Ensure 'transformers', 'datasets', etc. are installed)\n# !pip install -q transformers datasets accelerate torch evaluate scikit-learn pandas # Keep this if running fresh\n\n# 2. Imports (Keep imports as they were)\nimport torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    AutoConfig # Keep AutoConfig if needed later for inference loading\n)\nfrom datasets import Dataset, DatasetDict\nimport pandas as pd\nimport numpy as np\nimport os\n# from peft import LoraConfig, get_peft_model, TaskType, PeftModel # No longer needed for PEFT\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss\nfrom transformers import EvalPrediction\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# 3. Configuration (MODIFIED)\nMODEL_ID = \"xlm-roberta-base\" # <-- CHANGE Model ID\n# Or use \"xlm-roberta-large\" for potentially better performance but more memory usage\n\nTEST_CSV = \"/kaggle/input/unlp-2025-shared-task-classification-techniques/test.csv\"\nOUTPUT_DIR = \"xlm-roberta-multi-label-finetuned\" # <-- CHANGE Output directory\n# ADAPTER_SAVE_PATH = \"...\" # Not needed without LoRA\nSUBMISSION_FILE = \"submission_xlmr.csv\" # <-- CHANGE Submission filename\n\n# technique_columns definition remains the same\ntechnique_columns = [\n    'straw_man', 'appeal_to_fear', 'fud', 'bandwagon', 'whataboutism',\n    'loaded_language', 'glittering_generalities', 'euphoria',\n    'cherry_picking', 'cliche'\n]\nnum_labels = len(technique_columns)\n\n# Training Hyperparameters (MODIFIED for standard fine-tuning)\nLEARNING_RATE = 2e-5 # Typical range for BERT/RoBERTa: 2e-5 to 5e-5\nTRAIN_BATCH_SIZE = 8 # Can likely increase significantly vs Llama 3\nEVAL_BATCH_SIZE = 32 # Can likely increase\nNUM_EPOCHS = 15 # Might need a few more epochs than LoRA\nWEIGHT_DECAY = 0.01\nMAX_SEQ_LENGTH = 512 # Standard for RoBERTa\n\n# LoRA Configuration (DISABLED)\nUSE_LORA = False\n# Remove LORA_R, LORA_ALPHA, LORA_DROPOUT, LORA_TARGET_MODULES\n\n# Quantization Configuration (DISABLED)\nUSE_4BIT_QUANT = False\n# Remove bnb_config related lines\n\n# 4. Check GPU and Login (Keep this section as is)\nprint(\"\\nChecking GPU availability...\")\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n    total_gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n    print(f\"Total GPU Memory: {total_gpu_mem:.2f} GB\")\n    use_gpu = True\nelse:\n    device = torch.device(\"cpu\")\n    print(\"WARNING: GPU not found. Training will be very slow on CPU.\")\n    # Allow CPU training for smaller models like XLM-R, but warn user.\n    use_gpu = False\n\n# Optional Hugging Face Login (Keep as is)\n# from huggingface_hub import notebook_login\n# print(\"\\nPlease login to Hugging Face Hub (requires a token):\")\n# notebook_login()\n\nprint(f\"\\nConfiguration:\\nModel ID: {MODEL_ID}\\nNum Labels: {num_labels}\\nUse LoRA: {USE_LORA}\\nUse Quantization: {USE_4BIT_QUANT}\")\nprint(\"\\n--- Setup Complete ---\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:48:12.682757Z","iopub.execute_input":"2025-03-27T06:48:12.683045Z","iopub.status.idle":"2025-03-27T06:48:40.167588Z","shell.execute_reply.started":"2025-03-27T06:48:12.683021Z","shell.execute_reply":"2025-03-27T06:48:40.166621Z"}},"outputs":[{"name":"stdout","text":"\nChecking GPU availability...\nGPU is available: Tesla T4\nTotal GPU Memory: 14.74 GB\n\nConfiguration:\nModel ID: xlm-roberta-base\nNum Labels: 10\nUse LoRA: False\nUse Quantization: False\n\n--- Setup Complete ---\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T06:48:43.554009Z","iopub.execute_input":"2025-03-27T06:48:43.554693Z","iopub.status.idle":"2025-03-27T06:48:43.583040Z","shell.execute_reply.started":"2025-03-27T06:48:43.554663Z","shell.execute_reply":"2025-03-27T06:48:43.582111Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bba008976e254fd4937fa79c0472812f"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# --- Cell 2: Data Preparation (Revised for 'techniques' column) ---\n\nimport pandas as pd\nimport numpy as np\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nimport re # Import regular expressions for cleaning\n\n# Ensure configuration variables from Cell 1 are accessible\n# Required: TRAIN_CSV, technique_columns, MODEL_ID, MAX_SEQ_LENGTH\n\nprint(f\"Loading training data\")\ntry:\n    df_train_full = pd.read_csv(\"/kaggle/input/unlp-dataset/train.csv\")\n    # df_train_s = pd.read_csv(\"/kaggle/input/unlp-dataset/synthetic_train_dataset.csv\")\n    # df_train_s['techniques'] = df_train_s['techniques'].apply(\n    #     lambda x: [x] if isinstance(x, str) else x\n    # )\n\n    # df_train_full = pd.concat([df_train_full,df_train_s])\n    \n    # Basic text cleaning function\n    def clean_text(text):\n        text = text.lower() # Convert to lowercase\n        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n        text = re.sub(r'\\@\\w+|\\#', '', text) # Remove mentions and hashtags\n        text = re.sub(r'[^\\w\\s\\']', '', text) # Remove punctuation except apostrophes\n        text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n        return text\n    \n    # Apply cleaning to the 'content' column\n    df_train_full['content'] = df_train_full['content'].apply(clean_text)\n    \n    print(\"\\nSample of cleaned content:\")\n    print(df_train_full['content'].head())\n\n    # df_train_full['content'] = df_train_full['content'].fillna('').apply(clean_text)\n    df_train_full['content'] = df_train_full['content'].fillna('') # Ensure no NaN content\n    # Fill NaN values in 'techniques' with a string representation of an empty list\n    df_train_full['techniques'] = df_train_full['techniques'].fillna('[]')\nexcept FileNotFoundError:\n    print(f\"ERROR: Training file not found at {TRAIN_CSV}\")\n    raise\nexcept Exception as e:\n    print(f\"Error loading or processing {TRAIN_CSV}: {e}\")\n    raise\n\n# Verify required columns 'content' and 'techniques'\nif 'content' not in df_train_full.columns: raise ValueError(\"'content' column missing in train data.\")\nif 'techniques' not in df_train_full.columns: raise ValueError(\"'techniques' column missing in train data.\")\n\n# --- Define Label Parsing and Encoding Function ---\n# technique_columns should be defined in Cell 1\nif 'technique_columns' not in globals():\n     raise NameError(\"Variable 'technique_columns' not defined. Ensure Cell 1 was executed.\")\ntechnique_to_index = {name: i for i, name in enumerate(technique_columns)}\nnum_labels = len(technique_columns)\nunknown_techniques_found = set() # To track techniques not in our predefined list\n\n# --- Define Label Parsing and Encoding Function (REVISED) ---\n# technique_columns is defined in Cell 1\ntechnique_to_index = {name: i for i, name in enumerate(technique_columns)}\nnum_labels = len(technique_columns)\nunknown_techniques_found = set() # To track techniques not in our predefined list\n\ndef parse_and_encode_labels(technique_string):\n    \"\"\"\n    Parses the string representation from the 'techniques' column\n    (e.g., \"['tech1' 'tech2']\") and returns a multi-hot encoded\n    list of labels (float32).\n    \"\"\"\n    # Initialize label vector with zeros\n    labels = np.zeros(num_labels, dtype=np.float32)\n\n    # 1. Handle empty or invalid entries first\n    if not isinstance(technique_string, str) or technique_string.strip() in ('[]', '', 'nan'):\n        return labels.tolist() # Return all zeros\n\n    try:\n        # --- Revised Parsing Logic ---\n        # a. Remove outer brackets and leading/trailing whitespace\n        cleaned_str = technique_string.strip(\"[] \")\n\n        # b. Handle empty string after stripping brackets (e.g., if input was '[]')\n        if not cleaned_str:\n            return labels.tolist()\n\n        # c. Assume techniques are separated by spaces, potentially within single quotes\n        #    Replace the common separator \"' '\" (quote-space-quote) with a unique delimiter\n        #    Using regex substitution for robustness against multiple spaces between items\n        delimited_str = re.sub(r\"'\\s+'\", \"|\", cleaned_str) # Replace ' ' with |\n\n        # d. Remove any remaining single quotes (e.g., around the first/last item or if only one item)\n        delimited_str = delimited_str.replace(\"'\", \"\")\n\n        # e. Split the string by the delimiter\n        parsed_techniques = [tech.strip() for tech in delimited_str.split('|') if tech.strip()]\n\n        # --- Encoding Logic (remains the same) ---\n        if not parsed_techniques:\n             # This might happen if the format was unexpected, e.g. \"['']\"\n             return labels.tolist()\n\n        found_match = False\n        for tech_name in parsed_techniques:\n            if tech_name in technique_to_index:\n                labels[technique_to_index[tech_name]] = 1.0\n                found_match = True # Mark that at least one known technique was found\n            else:\n                # Optionally track or warn about techniques found in data but not expected\n                if tech_name not in unknown_techniques_found:\n                     print(f\"Warning: Technique '{tech_name}' found in data but not in predefined technique_columns. Ignoring.\")\n                     unknown_techniques_found.add(tech_name)\n\n        # Sanity check: If parsing resulted in something but no matches were found, print a warning\n        # This helps catch cases where parsing extracted unexpected strings.\n        # if parsed_techniques and not found_match:\n        #      print(f\"Warning: Parsed techniques {parsed_techniques} from '{technique_string}' but none matched known techniques.\")\n\n        return labels.tolist()\n\n    except Exception as e:\n        print(f\"Error parsing technique string: '{technique_string}'. Error: {e}. Returning all zeros.\")\n        # Return all zeros in case of unexpected error during parsing\n        return np.zeros(num_labels, dtype=np.float32).tolist()\n\n# --- Apply the function to create the 'labels' column ---\nprint(\"\\nParsing 'techniques' column and creating multi-hot encoded 'labels'...\")\ndf_train_full['labels'] = df_train_full['techniques'].apply(parse_and_encode_labels)\n\n# --- Verification ---\nprint(\"Example of created labels (first 5 rows):\")\nprint(df_train_full[['content','techniques', 'labels']].head())\n\n# Check if all label lists have the correct length\nlabel_lengths = df_train_full['labels'].apply(len)\nincorrect_length_count = (label_lengths != num_labels).sum()\nif incorrect_length_count > 0:\n    print(f\"\\nERROR: Found {incorrect_length_count} rows where the generated 'labels' list does not have the expected length ({num_labels})!\")\n    # Optionally print problematic rows:\n    # print(\"Problematic rows:\")\n    # print(df_train_full[label_lengths != num_labels][['techniques', 'labels']])\n    raise ValueError(\"Label length mismatch detected. Please check the parsing function or input data.\")\nelse:\n    print(f\"\\nVerified: All {len(df_train_full)} rows have a 'labels' list of length {num_labels}.\")\n\n\n# Select final columns needed for the dataset ('content' and the new 'labels')\ndf_train_final = df_train_full[['content', 'labels']]\n\nprint(df_train_final['labels'])\n\n# --- Split data into Training and Validation sets ---\nprint(\"\\nSplitting data into train/validation sets (90/10 split)...\")\ndf_train, df_val = train_test_split(df_train_final, test_size=0.1, random_state=42) # Adjust test_size if needed\n\n# --- Calculate Class Weights for BCEWithLogitsLoss ---\nprint(\"\\nCalculating positive class weights for loss function...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:03:00.949907Z","iopub.execute_input":"2025-03-27T07:03:00.950221Z","iopub.status.idle":"2025-03-27T07:03:01.392511Z","shell.execute_reply.started":"2025-03-27T07:03:00.950201Z","shell.execute_reply":"2025-03-27T07:03:01.391616Z"}},"outputs":[{"name":"stdout","text":"Loading training data\n\nSample of cleaned content:\n0    новий огляд мапи deepstate від російського вій...\n1    недавно 95 квартал жёстко поглумился над русск...\n2    тим часом йде евакуація бєлгородського автовок...\n3    в україні найближчим часом мають намір посилит...\n4    расчёты 122мм сау 2с1 гвоздика 132й бригады 1г...\nName: content, dtype: object\n\nParsing 'techniques' column and creating multi-hot encoded 'labels'...\nExample of created labels (first 5 rows):\n                                             content  \\\n0  новий огляд мапи deepstate від російського вій...   \n1  недавно 95 квартал жёстко поглумился над русск...   \n2  тим часом йде евакуація бєлгородського автовок...   \n3  в україні найближчим часом мають намір посилит...   \n4  расчёты 122мм сау 2с1 гвоздика 132й бригады 1г...   \n\n                             techniques  \\\n0        ['euphoria' 'loaded_language']   \n1  ['loaded_language' 'cherry_picking']   \n2        ['loaded_language' 'euphoria']   \n3                                    []   \n4                   ['loaded_language']   \n\n                                              labels  \n0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...  \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...  \n2  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...  \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n\nVerified: All 3822 rows have a 'labels' list of length 10.\n0       [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...\n1       [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...\n2       [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...\n3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n4       [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...\n                              ...                        \n3817    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...\n3818    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...\n3819    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n3820    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n3821    [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...\nName: labels, Length: 3822, dtype: object\n\nSplitting data into train/validation sets (90/10 split)...\n\nCalculating positive class weights for loss function...\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Use the training portion of the labels DataFrame (df_train contains 'labels' column)\ntrain_labels_np = np.array(df_train['labels'].tolist()) # N_train_samples x num_labels\n\npos_weights_list = []\nepsilon = 1e-6 # To avoid division by zero if a class has no positive examples\n\nfor i in range(num_labels): # num_labels defined in Cell 1\n    num_positive = train_labels_np[:, i].sum()\n    num_negative = len(train_labels_np) - num_positive\n\n    # Formula: pos_weight = num_negative / num_positive\n    # Add epsilon for numerical stability if num_positive is 0\n    pos_weight = num_negative / (num_positive + epsilon)\n    pos_weights_list.append(pos_weight)\n    print(f\"  Technique '{technique_columns[i]}': Positives={int(num_positive)}, Negatives={int(num_negative)}, PosWeight={pos_weight:.2f}\")\n\n# Convert weights to a PyTorch tensor (needs to be accessible in Cell 4)\n# Making it global for simplicity, or pass via a shared context if preferred\nglobal pos_weights_tensor\npos_weights_tensor = torch.tensor(pos_weights_list, dtype=torch.float32)\nprint(\"\\nPositive class weights tensor created:\")\nprint(pos_weights_tensor)\n\n# --- (Rest of Cell 2: Convert to DatasetDict, Tokenize, etc.) ---\n# ... (Keep the subsequent code in Cell 2) ...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:03:14.539550Z","iopub.execute_input":"2025-03-27T07:03:14.539874Z","iopub.status.idle":"2025-03-27T07:03:14.694816Z","shell.execute_reply.started":"2025-03-27T07:03:14.539848Z","shell.execute_reply":"2025-03-27T07:03:14.694064Z"}},"outputs":[{"name":"stdout","text":"  Technique 'straw_man': Positives=128, Negatives=3311, PosWeight=25.87\n  Technique 'appeal_to_fear': Positives=270, Negatives=3169, PosWeight=11.74\n  Technique 'fud': Positives=348, Negatives=3091, PosWeight=8.88\n  Technique 'bandwagon': Positives=138, Negatives=3301, PosWeight=23.92\n  Technique 'whataboutism': Positives=146, Negatives=3293, PosWeight=22.55\n  Technique 'loaded_language': Positives=1788, Negatives=1651, PosWeight=0.92\n  Technique 'glittering_generalities': Positives=444, Negatives=2995, PosWeight=6.75\n  Technique 'euphoria': Positives=418, Negatives=3021, PosWeight=7.23\n  Technique 'cherry_picking': Positives=463, Negatives=2976, PosWeight=6.43\n  Technique 'cliche': Positives=418, Negatives=3021, PosWeight=7.23\n\nPositive class weights tensor created:\ntensor([25.8672, 11.7370,  8.8822, 23.9203, 22.5548,  0.9234,  6.7455,  7.2273,\n         6.4276,  7.2273])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# --- Convert pandas DataFrames to Hugging Face Datasets ---\nprint(\"Converting to Hugging Face Dataset format...\")\nraw_dataset = DatasetDict({\n    'train': Dataset.from_pandas(df_train, preserve_index=False),\n    'validation': Dataset.from_pandas(df_val, preserve_index=False)\n})\n\nprint(\"\\nRaw Datasets:\")\nprint(raw_dataset)\n\n# --- Load Tokenizer ---\n# Ensure tokenizer is available from Cell 1 or load it here\n# --- Load Tokenizer (Ensure it matches MODEL_ID from Cell 1) ---\nprint(f\"\\nLoading tokenizer for {MODEL_ID}...\")\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n\n# XLM-RoBERTa usually has padding defined, but check just in case\nif tokenizer.pad_token is None:\n    print(\"Warning: Tokenizer does not have a pad token. Adding EOS token as pad token.\")\n    # Some models might need specific pad tokens, but EOS often works.\n    # Check XLM-R documentation if issues arise.\n    tokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = 'right' # Standard for classification\n\n# --- Tokenization Function (No changes needed in the function itself) ---\ndef tokenize_and_format(examples):\n    # Tokenize the text content\n    tokenized_inputs = tokenizer(\n        examples['content'],\n        truncation=True,       # Truncate sequences longer than max_seq_length\n        padding='max_length',  # Pad sequences to max_seq_length\n        max_length=MAX_SEQ_LENGTH,\n        # return_tensors='pt' # Trainer handles tensor conversion\n    )\n    # Ensure labels are included\n    tokenized_inputs['labels'] = examples['labels']\n    return tokenized_inputs\n\n# --- Apply tokenization (No changes needed) ---\nprint(\"\\nTokenizing datasets...\")\ntokenized_dataset = raw_dataset.map(\n    tokenize_and_format,\n    batched=True,\n    remove_columns=['content']\n)\n\n# --- Set format (No changes needed) ---\ntokenized_dataset.set_format(\"torch\")\n\nprint(\"\\nTokenized Datasets:\")\nprint(tokenized_dataset)\nprint(f\"Columns in tokenized train dataset: {tokenized_dataset['train'].column_names}\")\nprint(f\"\\nExample tokenized input:\\nText (IDs): {tokenized_dataset['train'][0]['input_ids'][:20]}...\\nAttention Mask: {tokenized_dataset['train'][0]['attention_mask'][:20]}...\\nLabels: {tokenized_dataset['train'][0]['labels']}\")\n\nprint(\"\\n--- Data Preparation Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:08:34.387248Z","iopub.execute_input":"2025-03-27T07:08:34.387619Z","iopub.status.idle":"2025-03-27T07:08:40.979217Z","shell.execute_reply.started":"2025-03-27T07:08:34.387588Z","shell.execute_reply":"2025-03-27T07:08:40.978370Z"}},"outputs":[{"name":"stdout","text":"Converting to Hugging Face Dataset format...\n\nRaw Datasets:\nDatasetDict({\n    train: Dataset({\n        features: ['content', 'labels'],\n        num_rows: 3439\n    })\n    validation: Dataset({\n        features: ['content', 'labels'],\n        num_rows: 383\n    })\n})\n\nLoading tokenizer for xlm-roberta-base...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dde15a0a8fb4f6096a4bc8e470d7f99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0771e351252140829c9902a0659be6ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18db26e8306140a4ac02e5d72a6abc93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bab6cfc941b47ac9dd691a49f89b113"}},"metadata":{}},{"name":"stdout","text":"\nTokenizing datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3439 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be647e707e00449da623c17732fe00bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/383 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"208afaa889c44e93870cc2b4dc9152a5"}},"metadata":{}},{"name":"stdout","text":"\nTokenized Datasets:\nDatasetDict({\n    train: Dataset({\n        features: ['labels', 'input_ids', 'attention_mask'],\n        num_rows: 3439\n    })\n    validation: Dataset({\n        features: ['labels', 'input_ids', 'attention_mask'],\n        num_rows: 383\n    })\n})\nColumns in tokenized train dataset: ['labels', 'input_ids', 'attention_mask']\n\nExample tokenized input:\nText (IDs): tensor([     0, 220007, 237041,    105,  52652,    260,  38565,   4335,  72681,\n         52503,     29,    805,   1045,   6173,   7310,  52432, 167254,    518,\n        119746,    105])...\nAttention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])...\nLabels: tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n\n--- Data Preparation Complete ---\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- Cell 3: Model Configuration & Loading (Simplified for XLM-RoBERTa) ---\n\nprint(f\"Loading model: {MODEL_ID}\")\n\n# 1. Load Base Model (No Quantization, No LoRA)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_ID,\n    num_labels=num_labels,\n    problem_type=\"multi_label_classification\", # Still multi-label\n    device_map=\"auto\", # Automatically use GPU if available\n    # trust_remote_code=True # Usually not needed for standard models like XLM-R\n    ignore_mismatched_sizes=True # Add this if loading base model weights into classification head causes size mismatch warnings (common and usually okay)\n)\n\n# 2. Handle Padding Token ID (Good practice, though usually set for XLM-R)\nif tokenizer.pad_token_id is not None and model.config.pad_token_id is None:\n     print(f\"Setting model's pad_token_id to tokenizer's: {tokenizer.pad_token_id}\")\n     model.config.pad_token_id = tokenizer.pad_token_id\nelif tokenizer.pad_token_id is None and model.config.pad_token_id is None:\n     print(\"Warning: Both tokenizer and model lack a pad_token_id.\")\n     # You might need to add one to the tokenizer and resize model embeddings if padding is necessary\n\n\nprint(f\"\\nModel loaded: {MODEL_ID}\")\n# Print model structure summary (optional)\n# print(model)\n# Verify model is on the correct device\nprint(f\"Model is on device: {model.device}\")\n\nprint(\"\\n--- Model Configuration & Loading Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:08:46.271825Z","iopub.execute_input":"2025-03-27T07:08:46.272109Z","iopub.status.idle":"2025-03-27T07:08:53.064742Z","shell.execute_reply.started":"2025-03-27T07:08:46.272087Z","shell.execute_reply":"2025-03-27T07:08:53.064063Z"}},"outputs":[{"name":"stdout","text":"Loading model: xlm-roberta-base\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aff5eafbc8df4254a51d8ff000613257"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nModel loaded: xlm-roberta-base\nModel is on device: cuda:0\n\n--- Model Configuration & Loading Complete ---\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T21:39:25.325453Z","iopub.execute_input":"2025-03-26T21:39:25.325912Z","iopub.status.idle":"2025-03-26T21:39:29.096854Z","shell.execute_reply.started":"2025-03-26T21:39:25.325871Z","shell.execute_reply":"2025-03-26T21:39:29.095890Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:09:17.654645Z","iopub.execute_input":"2025-03-27T07:09:17.654968Z","iopub.status.idle":"2025-03-27T07:09:22.966340Z","shell.execute_reply.started":"2025-03-27T07:09:17.654942Z","shell.execute_reply":"2025-03-27T07:09:22.965426Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# --- Cell 4: Training Configuration & Execution (Adjusted for XLM-RoBERTa) ---\nimport evaluate\nprint(\"Configuring Training...\")\n\n\nfrom torch.nn import BCEWithLogitsLoss # Import the loss function\n\n# --- Cell 4: Training Configuration & Execution (with Class Weights) ---\n\n# Imports for this cell\nimport torch\nfrom torch.nn import BCEWithLogitsLoss\nfrom transformers import Trainer, TrainingArguments, EvalPrediction\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss\nimport numpy as np\nimport evaluate # Use HF evaluate library\n\n# Check if pos_weights_tensor exists from Cell 2\nif 'pos_weights_tensor' not in globals():\n     raise NameError(\"Variable 'pos_weights_tensor' not found. Ensure Cell 2 defining it was executed.\")\n\n# 1. Define Metrics Computation Function\n# Using a threshold of 0.5 for F1/Hamming calculation during evaluation\ndef compute_metrics(p: EvalPrediction):\n    # Predictions are logits, labels are already multi-hot\n    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n    labels = p.label_ids.astype(np.float32) # Ensure labels are float32\n\n    if logits is None:\n         print(\"Warning: compute_metrics received None for predictions.\")\n         return {} # Return empty dict if predictions are None\n\n    # Check for NaN in logits before sigmoid\n    if np.isnan(logits).any():\n        print(\"ERROR: NaNs detected in model logits within compute_metrics! Returning zero metrics.\")\n        # Return default/zero metrics to avoid crashing Trainer evaluation loop\n        return {'f1_macro': 0.0, 'f1_micro': 0.0, 'hamming_loss': 1.0}\n\n    # Apply sigmoid activation to get probabilities\n    sigmoid_preds = 1 / (1 + np.exp(-logits)) # Sigmoid function\n\n    # Apply threshold (0.5) to get binary predictions\n    binary_preds = (sigmoid_preds > 0.5).astype(int)\n\n    # Calculate metrics using sklearn\n    try:\n        f1_macro = f1_score(y_true=labels, y_pred=binary_preds, average='macro', zero_division=0)\n        f1_micro = f1_score(y_true=labels, y_pred=binary_preds, average='micro', zero_division=0)\n        # f1_weighted = f1_score(y_true=labels, y_pred=binary_preds, average='weighted', zero_division=0)\n        # f1_samples = f1_score(y_true=labels, y_pred=binary_preds, average='samples', zero_division=0)\n        hamming = hamming_loss(y_true=labels, y_pred=binary_preds)\n\n        return {\n            'f1_macro': f1_macro,\n            'f1_micro': f1_micro,\n            # 'f1_weighted': f1_weighted,\n            # 'f1_samples': f1_samples,\n            'hamming_loss': hamming\n        }\n    except Exception as e:\n        print(f\"Error calculating metrics: {e}. Returning zero metrics.\")\n        return {'f1_macro': 0.0, 'f1_micro': 0.0, 'hamming_loss': 1.0}\n\n# --- Define Custom Trainer to Apply Class Weights (Corrected for DataParallel) ---\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        \"\"\"\n        Overrides the default loss computation to use BCEWithLogitsLoss with pos_weight.\n        Handles models potentially wrapped by DataParallel/DistributedDataParallel.\n        Accepts **kwargs to handle unexpected arguments passed by Trainer.\n        \"\"\"\n        if 'pos_weights_tensor' not in globals():\n             raise NameError(\"pos_weights_tensor not found in global scope for CustomTrainer.\")\n\n        labels = inputs.pop(\"labels\").float()\n        outputs = model(**inputs) # model here might be the DataParallel wrapper\n        logits = outputs.get(\"logits\")\n\n        # --- Get device correctly, handling DataParallel ---\n        if hasattr(model, 'module'):\n            model_device = model.module.device # Access device from underlying module\n        else:\n            model_device = model.device # Access device directly\n        # -------------------------------------------------\n\n        weights = pos_weights_tensor.to(model_device) # Move weights to the correct device\n        loss_fct = BCEWithLogitsLoss(pos_weight=weights)\n        loss = loss_fct(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss\n# --- End of Custom Trainer Definition ---\n\n# 2. Define Training Arguments (Adjust as needed, e.g., add save_total_limit)\nprint(\"Setting Training Arguments...\")\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    num_train_epochs=NUM_EPOCHS,\n    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n    learning_rate=LEARNING_RATE,\n    weight_decay=WEIGHT_DECAY,\n    logging_dir=f'{OUTPUT_DIR}/logs',\n    logging_strategy=\"steps\",\n    logging_steps=max(10, int(len(tokenized_dataset[\"train\"]) / (TRAIN_BATCH_SIZE * torch.cuda.device_count() if torch.cuda.is_available() else 1 ) / 10)),\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_macro\", # Focus on Macro F1\n    greater_is_better=True,\n    save_total_limit=2, # Keep only the best and the latest checkpoint (suggestion 2)\n    fp16=use_gpu, # Enable if using GPU\n    report_to=\"none\",\n)\n\n# 3. Initialize Trainer --> Use CustomTrainer <--\nprint(\"Initializing CustomTrainer...\")\ntrainer = CustomTrainer( # <-- Use the custom class\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics, # Your existing function\n)\n\n# 4. Start Training\nprint(\"\\n--- Starting Training with Custom Loss ---\")\ntorch.cuda.empty_cache()\ntrain_result = trainer.train()\n\n# 5. Save Training Metrics & Final Model (Keep as is)\n# ... (Keep saving logic) ...\n\nprint(\"\\n--- Training Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:14:54.442926Z","iopub.execute_input":"2025-03-27T07:14:54.443251Z","iopub.status.idle":"2025-03-27T08:01:12.049100Z","shell.execute_reply.started":"2025-03-27T07:14:54.443226Z","shell.execute_reply":"2025-03-27T08:01:12.047897Z"}},"outputs":[{"name":"stdout","text":"Configuring Training...\nSetting Training Arguments...\nInitializing CustomTrainer...\n\n--- Starting Training with Custom Loss ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2373' max='3225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2373/3225 46:14 < 16:36, 0.85 it/s, Epoch 11.03/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1 Macro</th>\n      <th>F1 Micro</th>\n      <th>Hamming Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.136500</td>\n      <td>1.106488</td>\n      <td>0.245509</td>\n      <td>0.261957</td>\n      <td>0.354569</td>\n      <td>6.893500</td>\n      <td>55.559000</td>\n      <td>0.870000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.050500</td>\n      <td>0.967286</td>\n      <td>0.309029</td>\n      <td>0.351320</td>\n      <td>0.295039</td>\n      <td>6.921900</td>\n      <td>55.332000</td>\n      <td>0.867000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.915200</td>\n      <td>0.973558</td>\n      <td>0.359606</td>\n      <td>0.410635</td>\n      <td>0.208355</td>\n      <td>6.968400</td>\n      <td>54.963000</td>\n      <td>0.861000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.848600</td>\n      <td>0.921028</td>\n      <td>0.357716</td>\n      <td>0.426319</td>\n      <td>0.218538</td>\n      <td>6.928900</td>\n      <td>55.275000</td>\n      <td>0.866000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.722200</td>\n      <td>0.952976</td>\n      <td>0.362068</td>\n      <td>0.435495</td>\n      <td>0.215927</td>\n      <td>6.912500</td>\n      <td>55.407000</td>\n      <td>0.868000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.664400</td>\n      <td>1.054844</td>\n      <td>0.359668</td>\n      <td>0.442560</td>\n      <td>0.188773</td>\n      <td>6.918400</td>\n      <td>55.359000</td>\n      <td>0.867000</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.633000</td>\n      <td>1.103434</td>\n      <td>0.379631</td>\n      <td>0.484026</td>\n      <td>0.168668</td>\n      <td>6.909000</td>\n      <td>55.435000</td>\n      <td>0.868000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.609900</td>\n      <td>1.189787</td>\n      <td>0.373412</td>\n      <td>0.460999</td>\n      <td>0.160574</td>\n      <td>6.935000</td>\n      <td>55.227000</td>\n      <td>0.865000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.501300</td>\n      <td>1.349015</td>\n      <td>0.334315</td>\n      <td>0.440617</td>\n      <td>0.161097</td>\n      <td>6.923600</td>\n      <td>55.318000</td>\n      <td>0.867000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.486000</td>\n      <td>1.349858</td>\n      <td>0.352266</td>\n      <td>0.477048</td>\n      <td>0.151697</td>\n      <td>6.956800</td>\n      <td>55.054000</td>\n      <td>0.862000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.414300</td>\n      <td>1.442606</td>\n      <td>0.357546</td>\n      <td>0.477756</td>\n      <td>0.140992</td>\n      <td>6.910700</td>\n      <td>55.421000</td>\n      <td>0.868000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-9cf3cc1589f0>\u001b[0m in \u001b[0;36m<cell line: 129>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Starting Training with Custom Loss ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;31m# 5. Save Training Metrics & Final Model (Keep as is)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m                     ):\n\u001b[1;32m   2529\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"# import shutil\n\n# # Список чекпоінтів, які хочеш видалити\n# checkpoints_to_delete = [\n#     \"checkpoint-356\",\n#     \"checkpoint-712\",\n#     \"checkpoint-1068\",\n#     \"checkpoint-1424\",\n#     \"checkpoint-1780\"\n# ]\n\n# for checkpoint in checkpoints_to_delete:\n#     path = f\"/kaggle/working/xlm-roberta-multi-label-finetuned/{checkpoint}\"\n#     shutil.rmtree(path, ignore_errors=True)\n#     print(f\"Deleted: {checkpoint}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T22:20:27.071303Z","iopub.execute_input":"2025-03-26T22:20:27.071642Z","iopub.status.idle":"2025-03-26T22:20:28.656186Z","shell.execute_reply.started":"2025-03-26T22:20:27.071616Z","shell.execute_reply":"2025-03-26T22:20:28.655197Z"}},"outputs":[{"name":"stdout","text":"Deleted: checkpoint-356\nDeleted: checkpoint-712\nDeleted: checkpoint-1068\nDeleted: checkpoint-1424\nDeleted: checkpoint-1780\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Cell 5: Inference & Submission (Adjusted for Loading from Checkpoint) ---\nimport math\nfrom transformers import AutoConfig # Make sure AutoConfig is imported\n\nprint(\"--- Starting Inference and Submission File Generation ---\")\n\n# --- Specify the path to the BEST checkpoint directory ---\n# Replace 'checkpoint-XXXX' with the actual directory name identified as the best\n# Based on your image and logs (Epoch 5 best), let's assume it might be checkpoint-2365\n# VERIFY THIS from your full logs or trainer_state.json if possible!\nbest_checkpoint_path = os.path.join(OUTPUT_DIR, \"checkpoint-2365\") # Or \"checkpoint-1505\", etc.\nprint(f\"Attempting to load fine-tuned model from: {best_checkpoint_path}\")\n#------------------------------------------------------------\n\n# 1. Load Fine-tuned Model for Inference from the Checkpoint\ntry:\n    inference_model = AutoModelForSequenceClassification.from_pretrained(\n        best_checkpoint_path, # <-- Load from the specific checkpoint path\n        device_map=\"auto\" # Load onto GPU if available\n    )\n    # Load the tokenizer associated with the fine-tuned model/checkpoint\n    tokenizer = AutoTokenizer.from_pretrained(best_checkpoint_path)\n\n    # Ensure model is on the correct device and in evaluation mode\n    inference_model.to(device) # device should be defined from Cell 1 ('cuda' or 'cpu')\n    inference_model.eval()\n    print(\"Model and tokenizer loaded successfully from checkpoint and set to evaluation mode.\")\n\nexcept OSError as e:\n     print(f\"ERROR loading model from {best_checkpoint_path}: {e}\")\n     print(\"Please ensure the checkpoint path is correct and contains the model files.\")\n     print(f\"Files in {OUTPUT_DIR}: {os.listdir(OUTPUT_DIR)}\")\n     if os.path.exists(best_checkpoint_path):\n         print(f\"Files in {best_checkpoint_path}: {os.listdir(best_checkpoint_path)}\")\n     raise SystemExit(\"Stopping due to model loading error.\")\n\n\n# 2. Load Test Data (Keep as is)\nprint(f\"\\nLoading test data from: {TEST_CSV}\")\n# ... (rest of test data loading code) ...\ntry:\n    df_test = pd.read_csv(TEST_CSV)\n    if 'id' not in df_test.columns: raise ValueError(\"'id' column missing in test data.\")\n    if 'content' not in df_test.columns: raise ValueError(\"'content' column missing in test data.\")\n    df_test['content'] = df_test['content'].fillna('')\n    # Apply the same basic cleaning if done during training\n    # df_test['content'] = df_test['content'].apply(clean_text)\nexcept FileNotFoundError:\n    print(f\"ERROR: Test file not found at {TEST_CSV}\")\n    raise\nexcept Exception as e:\n    print(f\"Error loading or processing {TEST_CSV}: {e}\")\n    raise\nprint(f\"Test data loaded. Shape: {df_test.shape}\")\n\n\n# 3. Predict on Test Data (Using Batches - Keep as is)\nprint(\"\\nGenerating predictions on test data...\")\n# ... (rest of prediction loop code using 'inference_model' and 'tokenizer') ...\nresults = []\ntest_texts = df_test['content'].tolist()\ninference_batch_size = EVAL_BATCH_SIZE * 2 # Use eval batch size or larger defined in Cell 1\n\nnum_batches = math.ceil(len(test_texts) / inference_batch_size)\n\nwith torch.no_grad():\n    for i in range(0, len(test_texts), inference_batch_size):\n        batch_texts = test_texts[i : i + inference_batch_size]\n\n        inputs = tokenizer(\n            batch_texts,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=MAX_SEQ_LENGTH # MAX_SEQ_LENGTH defined in Cell 1\n        ).to(device) # Move input tensors to the correct device\n\n        outputs = inference_model(**inputs)\n        logits = outputs.logits\n        probabilities = torch.sigmoid(logits)\n        predictions = (probabilities > 0.5).cpu().numpy().astype(int) # Thresholding\n        results.extend(predictions.tolist())\n        print(f\"  Processed batch {i // inference_batch_size + 1} / {num_batches}\")\n\nprint(\"\\nPredictions generated.\")\n\n\n# 4. Create Submission File (Keep as is, using SUBMISSION_FILE defined in Cell 1)\nprint(\"Creating submission file...\")\n# ... (rest of submission file creation code) ...\ndf_predictions = pd.DataFrame(results, columns=technique_columns) # technique_columns defined in Cell 1\ndf_submission = pd.concat([df_test[['id']], df_predictions], axis=1)\nexpected_submission_columns = ['id'] + list(technique_columns)\nif list(df_submission.columns) != expected_submission_columns:\n     print(\"Warning: Column order mismatch in submission df. Reordering...\")\n     df_submission = df_submission[expected_submission_columns]\n\nprint(f\"\\nSubmission DataFrame preview (first 5 rows):\")\nprint(df_submission.head())\n\n# Save to CSV\ntry:\n    df_submission.to_csv(SUBMISSION_FILE, index=False) # Use SUBMISSION_FILE variable\n    print(f\"\\nSubmission file created successfully at: {SUBMISSION_FILE}\")\n    # Optional: Download link for Colab\n    # from google.colab import files\n    # files.download(SUBMISSION_FILE)\nexcept Exception as e:\n    print(f\"\\nError saving submission file: {e}\")\n\nprint(\"\\n--- Inference and Submission Complete ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T08:06:11.004636Z","iopub.execute_input":"2025-03-27T08:06:11.004937Z","iopub.status.idle":"2025-03-27T08:09:19.710140Z","shell.execute_reply.started":"2025-03-27T08:06:11.004915Z","shell.execute_reply":"2025-03-27T08:09:19.709414Z"}},"outputs":[{"name":"stdout","text":"--- Starting Inference and Submission File Generation ---\nAttempting to load fine-tuned model from: xlm-roberta-multi-label-finetuned/checkpoint-2365\nModel and tokenizer loaded successfully from checkpoint and set to evaluation mode.\n\nLoading test data from: /kaggle/input/unlp-2025-shared-task-classification-techniques/test.csv\nTest data loaded. Shape: (5735, 2)\n\nGenerating predictions on test data...\n  Processed batch 1 / 90\n  Processed batch 2 / 90\n  Processed batch 3 / 90\n  Processed batch 4 / 90\n  Processed batch 5 / 90\n  Processed batch 6 / 90\n  Processed batch 7 / 90\n  Processed batch 8 / 90\n  Processed batch 9 / 90\n  Processed batch 10 / 90\n  Processed batch 11 / 90\n  Processed batch 12 / 90\n  Processed batch 13 / 90\n  Processed batch 14 / 90\n  Processed batch 15 / 90\n  Processed batch 16 / 90\n  Processed batch 17 / 90\n  Processed batch 18 / 90\n  Processed batch 19 / 90\n  Processed batch 20 / 90\n  Processed batch 21 / 90\n  Processed batch 22 / 90\n  Processed batch 23 / 90\n  Processed batch 24 / 90\n  Processed batch 25 / 90\n  Processed batch 26 / 90\n  Processed batch 27 / 90\n  Processed batch 28 / 90\n  Processed batch 29 / 90\n  Processed batch 30 / 90\n  Processed batch 31 / 90\n  Processed batch 32 / 90\n  Processed batch 33 / 90\n  Processed batch 34 / 90\n  Processed batch 35 / 90\n  Processed batch 36 / 90\n  Processed batch 37 / 90\n  Processed batch 38 / 90\n  Processed batch 39 / 90\n  Processed batch 40 / 90\n  Processed batch 41 / 90\n  Processed batch 42 / 90\n  Processed batch 43 / 90\n  Processed batch 44 / 90\n  Processed batch 45 / 90\n  Processed batch 46 / 90\n  Processed batch 47 / 90\n  Processed batch 48 / 90\n  Processed batch 49 / 90\n  Processed batch 50 / 90\n  Processed batch 51 / 90\n  Processed batch 52 / 90\n  Processed batch 53 / 90\n  Processed batch 54 / 90\n  Processed batch 55 / 90\n  Processed batch 56 / 90\n  Processed batch 57 / 90\n  Processed batch 58 / 90\n  Processed batch 59 / 90\n  Processed batch 60 / 90\n  Processed batch 61 / 90\n  Processed batch 62 / 90\n  Processed batch 63 / 90\n  Processed batch 64 / 90\n  Processed batch 65 / 90\n  Processed batch 66 / 90\n  Processed batch 67 / 90\n  Processed batch 68 / 90\n  Processed batch 69 / 90\n  Processed batch 70 / 90\n  Processed batch 71 / 90\n  Processed batch 72 / 90\n  Processed batch 73 / 90\n  Processed batch 74 / 90\n  Processed batch 75 / 90\n  Processed batch 76 / 90\n  Processed batch 77 / 90\n  Processed batch 78 / 90\n  Processed batch 79 / 90\n  Processed batch 80 / 90\n  Processed batch 81 / 90\n  Processed batch 82 / 90\n  Processed batch 83 / 90\n  Processed batch 84 / 90\n  Processed batch 85 / 90\n  Processed batch 86 / 90\n  Processed batch 87 / 90\n  Processed batch 88 / 90\n  Processed batch 89 / 90\n  Processed batch 90 / 90\n\nPredictions generated.\nCreating submission file...\n\nSubmission DataFrame preview (first 5 rows):\n                                     id  straw_man  appeal_to_fear  fud  \\\n0  521cd2e8-dd9f-42c4-98ba-c0c8890ff1ba          0               1    1   \n1  9b2a61e4-d14e-4ff7-b304-e73d720319bf          0               0    0   \n2  f0f1c236-80a8-4d25-b30c-a420a39be632          0               0    0   \n3  31ea05ba-2c2b-4b84-aba7-f3cf6841b204          0               0    0   \n4  a79e13ec-6d9a-40b5-b54c-7f4f743a7525          0               0    0   \n\n   bandwagon  whataboutism  loaded_language  glittering_generalities  \\\n0          0             0                1                        0   \n1          0             0                0                        0   \n2          0             0                0                        0   \n3          0             0                0                        0   \n4          0             0                0                        0   \n\n   euphoria  cherry_picking  cliche  \n0         1               1       1  \n1         0               0       0  \n2         0               0       0  \n3         0               0       0  \n4         0               0       0  \n\nSubmission file created successfully at: submission_xlmr.csv\n\n--- Inference and Submission Complete ---\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(SUBMISSION_FILE)\n\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T08:11:18.962174Z","iopub.execute_input":"2025-03-27T08:11:18.962528Z","iopub.status.idle":"2025-03-27T08:11:18.995907Z","shell.execute_reply.started":"2025-03-27T08:11:18.962501Z","shell.execute_reply":"2025-03-27T08:11:18.995245Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                        id  straw_man  appeal_to_fear  fud  \\\n0     521cd2e8-dd9f-42c4-98ba-c0c8890ff1ba          0               1    1   \n1     9b2a61e4-d14e-4ff7-b304-e73d720319bf          0               0    0   \n2     f0f1c236-80a8-4d25-b30c-a420a39be632          0               0    0   \n3     31ea05ba-2c2b-4b84-aba7-f3cf6841b204          0               0    0   \n4     a79e13ec-6d9a-40b5-b54c-7f4f743a7525          0               0    0   \n...                                    ...        ...             ...  ...   \n5730  e8e22b6d-0068-4afb-b606-4a1baa8a8d4c          0               0    1   \n5731  8b1d69b4-69ce-4e40-b4ba-dd2f370a8b6f          0               0    1   \n5732  c2246217-3358-4f61-bda8-e2ec21aed5b2          0               0    0   \n5733  45aa63c4-2248-4a0e-8f66-f3d23b6828ed          0               0    0   \n5734  5e68b0a8-e87c-45a3-a53a-7bde2e73471a          0               0    0   \n\n      bandwagon  whataboutism  loaded_language  glittering_generalities  \\\n0             0             0                1                        0   \n1             0             0                0                        0   \n2             0             0                0                        0   \n3             0             0                0                        0   \n4             0             0                0                        0   \n...         ...           ...              ...                      ...   \n5730          1             0                1                        0   \n5731          0             0                1                        0   \n5732          0             0                0                        0   \n5733          0             0                0                        0   \n5734          0             0                0                        0   \n\n      euphoria  cherry_picking  cliche  \n0            1               1       1  \n1            0               0       0  \n2            0               0       0  \n3            0               0       0  \n4            0               0       0  \n...        ...             ...     ...  \n5730         0               1       1  \n5731         0               1       0  \n5732         0               0       0  \n5733         0               0       0  \n5734         0               0       0  \n\n[5735 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>straw_man</th>\n      <th>appeal_to_fear</th>\n      <th>fud</th>\n      <th>bandwagon</th>\n      <th>whataboutism</th>\n      <th>loaded_language</th>\n      <th>glittering_generalities</th>\n      <th>euphoria</th>\n      <th>cherry_picking</th>\n      <th>cliche</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>521cd2e8-dd9f-42c4-98ba-c0c8890ff1ba</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9b2a61e4-d14e-4ff7-b304-e73d720319bf</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f0f1c236-80a8-4d25-b30c-a420a39be632</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31ea05ba-2c2b-4b84-aba7-f3cf6841b204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a79e13ec-6d9a-40b5-b54c-7f4f743a7525</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5730</th>\n      <td>e8e22b6d-0068-4afb-b606-4a1baa8a8d4c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5731</th>\n      <td>8b1d69b4-69ce-4e40-b4ba-dd2f370a8b6f</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5732</th>\n      <td>c2246217-3358-4f61-bda8-e2ec21aed5b2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5733</th>\n      <td>45aa63c4-2248-4a0e-8f66-f3d23b6828ed</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5734</th>\n      <td>5e68b0a8-e87c-45a3-a53a-7bde2e73471a</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5735 rows × 11 columns</p>\n</div>"},"metadata":{}}],"execution_count":17}]}